"""
Audit Bridge - Seamless audit execution for Claude Code.

This module provides functionality to parse, validate, split, and execute
audit documents generated by Claude.ai.
"""

from __future__ import annotations

import re
import shutil
import subprocess
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any

# =============================================================================
# Constants
# =============================================================================

PHASER_VERSION = "1.6.0"

SETUP_START_MARKER = "=== AUDIT SETUP START ==="
SETUP_END_MARKER = "=== AUDIT SETUP END ==="

DOCUMENT_HEADER_PATTERN = re.compile(r"^# Document (\d+):\s*(.+)$", re.MULTILINE)
PHASE_HEADER_PATTERN = re.compile(r"^## Phase (\d+):\s*(.+)$", re.MULTILINE)
COMPLETION_HEADER_PATTERN = re.compile(r"^## Document Completion", re.MULTILINE)

TOKEN_WARNING_THRESHOLD = 20000
TOKEN_ERROR_THRESHOLD = 25000

# =============================================================================
# Errors
# =============================================================================


class BridgeError(Exception):
    """Base error for bridge operations."""

    pass


class ParseError(BridgeError):
    """Error parsing audit document."""

    def __init__(self, message: str, line: int | None = None):
        self.line = line
        full_message = f"{message}" + (f" (line {line})" if line else "")
        super().__init__(full_message)


class ValidationError(BridgeError):
    """Error validating audit document structure."""

    def __init__(self, message: str, issues: list[ValidationIssue] | None = None):
        self.issues = issues or []
        super().__init__(message)


class ExecutionError(BridgeError):
    """Error executing audit."""

    pass


# =============================================================================
# Enums
# =============================================================================


class FileAction(str, Enum):
    """Action type for files in a phase."""

    CREATE = "CREATE"
    MODIFY = "MODIFY"
    DELETE = "DELETE"


# =============================================================================
# Data Classes
# =============================================================================


@dataclass
class ValidationIssue:
    """A single validation error or warning."""

    level: str  # "error" or "warning"
    phase: int | None  # Phase number, or None for document-level
    line: int | None  # Line number, if applicable
    message: str  # Human-readable message

    def to_dict(self) -> dict[str, Any]:
        return {
            "level": self.level,
            "phase": self.phase,
            "line": self.line,
            "message": self.message,
        }


@dataclass
class ValidationResult:
    """Result of document validation."""

    valid: bool  # True if no errors
    errors: list[ValidationIssue] = field(default_factory=list)
    warnings: list[ValidationIssue] = field(default_factory=list)

    source_path: str | None = None
    document_title: str | None = None
    phase_count: int = 0
    phase_range: str | None = None
    token_estimates: dict[str, int] = field(default_factory=dict)

    def to_dict(self) -> dict[str, Any]:
        return {
            "file": self.source_path,
            "valid": self.valid,
            "document": {
                "title": self.document_title,
                "phases": self.phase_count,
                "phase_range": self.phase_range,
            },
            "errors": [e.to_dict() for e in self.errors],
            "warnings": [w.to_dict() for w in self.warnings],
            "tokens": self.token_estimates,
        }


@dataclass
class PhaseFile:
    """A file entry from the Files table."""

    path: str  # "tools/reverse.py"
    action: FileAction  # CREATE, MODIFY, DELETE
    purpose: str  # "Reverse audit module"

    def to_dict(self) -> dict[str, Any]:
        return {
            "path": self.path,
            "action": self.action.value,
            "purpose": self.purpose,
        }


@dataclass
class Phase:
    """A single phase from an audit document."""

    number: int  # 36
    title: str  # "Reverse Audit Specification"

    context: str = ""
    goal: str = ""
    files: list[PhaseFile] = field(default_factory=list)
    plan: list[str] = field(default_factory=list)
    implementation: str = ""
    verify: str = ""
    acceptance_criteria: list[str] = field(default_factory=list)
    rollback: str = ""
    completion: str = ""

    raw_content: str = ""
    line_start: int = 0

    @property
    def estimated_tokens(self) -> int:
        """Estimate token count (conservative: 1 token per 3.5 chars)."""
        return int(len(self.raw_content) / 3.5)

    def to_dict(self) -> dict[str, Any]:
        return {
            "number": self.number,
            "title": self.title,
            "files": [f.to_dict() for f in self.files],
            "estimated_tokens": self.estimated_tokens,
            "line_start": self.line_start,
        }


@dataclass
class AuditDocument:
    """Parsed audit document."""

    title: str  # "Document 7: Reverse Audit"
    document_number: int  # 7
    source_path: Path | None = None

    overview: str | None = None
    prerequisites: str | None = None

    phases: list[Phase] = field(default_factory=list)
    setup_block: str = ""
    completion_block: str | None = None

    raw_content: str = ""

    @property
    def phase_count(self) -> int:
        return len(self.phases)

    @property
    def phase_start(self) -> int:
        return self.phases[0].number if self.phases else 0

    @property
    def phase_end(self) -> int:
        return self.phases[-1].number if self.phases else 0

    @property
    def phase_range(self) -> str:
        return f"{self.phase_start}-{self.phase_end}"

    def to_dict(self) -> dict[str, Any]:
        return {
            "title": self.title,
            "document_number": self.document_number,
            "source_path": str(self.source_path) if self.source_path else None,
            "overview": self.overview,
            "prerequisites": self.prerequisites,
            "phases": [p.to_dict() for p in self.phases],
            "phase_start": self.phase_start,
            "phase_end": self.phase_end,
            "phase_count": self.phase_count,
        }


@dataclass
class PrepareResult:
    """Result of preparing an audit for execution."""

    document: AuditDocument
    validation: ValidationResult
    project_dir: Path
    audit_phases_dir: Path
    meta_dir: Path

    setup_file: Path
    phase_files: list[Path] = field(default_factory=list)
    audit_copy: Path | None = None

    prompt: str = ""

    def to_dict(self) -> dict[str, Any]:
        return {
            "document": self.document.to_dict(),
            "validation": self.validation.to_dict(),
            "project_dir": str(self.project_dir),
            "setup_file": str(self.setup_file),
            "phase_files": [str(p) for p in self.phase_files],
            "audit_copy": str(self.audit_copy) if self.audit_copy else None,
        }


# =============================================================================
# Parsing Functions
# =============================================================================


def estimate_tokens(text: str) -> int:
    """Estimate token count. Conservative: 1 token per 3.5 characters."""
    return int(len(text) / 3.5)


def extract_setup_block(content: str) -> str:
    """
    Extract setup block content between markers.

    Args:
        content: Full document content

    Returns:
        Setup block content (including markers)

    Raises:
        ParseError: If markers not found
    """
    start_idx = content.find(SETUP_START_MARKER)
    if start_idx == -1:
        raise ParseError(
            f"Setup block not found. Expected '{SETUP_START_MARKER}' marker."
        )

    end_idx = content.find(SETUP_END_MARKER)
    if end_idx == -1:
        raise ParseError(
            f"Setup block not closed. Expected '{SETUP_END_MARKER}' marker."
        )

    return content[start_idx : end_idx + len(SETUP_END_MARKER)]


def extract_prerequisites(content: str) -> str | None:
    """
    Extract Prerequisites section content.

    Args:
        content: Full document content

    Returns:
        Prerequisites content, or None if not found
    """
    pattern = re.compile(
        r"^## Prerequisites\s*\n(.*?)(?=^## |\Z)", re.MULTILINE | re.DOTALL
    )
    match = pattern.search(content)
    if match:
        return match.group(0).strip()
    return None


def parse_baseline_test_count(prerequisites: str | None) -> int:
    """
    Parse the baseline test count from Prerequisites section.

    Args:
        prerequisites: Prerequisites section content

    Returns:
        Baseline test count (0 if not found or unparseable)
    """
    if not prerequisites:
        return 0

    # Look for patterns like "280+ passed" or "Expected: 280+ passed"
    pattern = re.compile(r"(\d+)\+?\s*passed", re.IGNORECASE)
    match = pattern.search(prerequisites)
    if match:
        return int(match.group(1))
    return 0


def extract_overview(content: str) -> str | None:
    """
    Extract Document Overview section content.

    Args:
        content: Full document content

    Returns:
        Overview content, or None if not found
    """
    pattern = re.compile(
        r"^## Document Overview\s*\n(.*?)(?=^## |\n---|\Z)", re.MULTILINE | re.DOTALL
    )
    match = pattern.search(content)
    if match:
        return match.group(1).strip()
    return None


def extract_completion_block(content: str) -> str | None:
    """
    Extract Document Completion section content.

    Args:
        content: Full document content

    Returns:
        Completion content, or None if not found
    """
    match = COMPLETION_HEADER_PATTERN.search(content)
    if match:
        return content[match.start() :].strip()
    return None


def detect_phase_boundaries(content: str) -> list[tuple[int, int, int]]:
    """
    Detect phase boundaries in document.

    Args:
        content: Full document content

    Returns:
        List of (phase_number, start_index, end_index) tuples
    """
    boundaries = []
    matches = list(PHASE_HEADER_PATTERN.finditer(content))

    for i, match in enumerate(matches):
        phase_num = int(match.group(1))
        start_idx = match.start()

        # End is either next phase, Document Completion, or end of content
        if i + 1 < len(matches):
            end_idx = matches[i + 1].start()
        else:
            # Check for Document Completion
            completion_match = COMPLETION_HEADER_PATTERN.search(content, start_idx)
            if completion_match:
                end_idx = completion_match.start()
            else:
                end_idx = len(content)

        boundaries.append((phase_num, start_idx, end_idx))

    return boundaries


def parse_files_table(content: str) -> list[PhaseFile]:
    """
    Parse the Files table from phase content.

    Args:
        content: Phase content containing Files section

    Returns:
        List of PhaseFile objects
    """
    files = []

    # Find the Files section
    files_match = re.search(
        r"### Files\s*\n(.*?)(?=^### |\Z)", content, re.MULTILINE | re.DOTALL
    )
    if not files_match:
        return files

    table_content = files_match.group(1)

    # Parse table rows (skip header and separator)
    row_pattern = re.compile(r"\|\s*`?([^`|]+)`?\s*\|\s*(\w+)\s*\|\s*([^|]+)\s*\|")
    for match in row_pattern.finditer(table_content):
        path = match.group(1).strip()
        action_str = match.group(2).strip().upper()
        purpose = match.group(3).strip()

        # Skip header row
        if path.lower() in ("file", "---", "------"):
            continue

        try:
            action = FileAction(action_str)
            files.append(PhaseFile(path=path, action=action, purpose=purpose))
        except ValueError:
            # Invalid action, skip
            pass

    return files


def parse_section(content: str, section_name: str) -> str:
    """
    Parse a specific section from phase content.

    Args:
        content: Phase content
        section_name: Name of section (e.g., "Context", "Goal")

    Returns:
        Section content, or empty string if not found
    """
    pattern = re.compile(
        rf"^### {section_name}\s*\n(.*?)(?=^### |\Z)", re.MULTILINE | re.DOTALL
    )
    match = pattern.search(content)
    if match:
        return match.group(1).strip()
    return ""


def parse_acceptance_criteria(content: str) -> list[str]:
    """
    Parse acceptance criteria checkboxes from phase content.

    Args:
        content: Phase content

    Returns:
        List of criteria strings
    """
    criteria = []
    section = parse_section(content, "Acceptance Criteria")
    if section:
        # Match checkbox items
        pattern = re.compile(r"^- \[[ x]\]\s*(.+)$", re.MULTILINE)
        for match in pattern.finditer(section):
            criteria.append(match.group(1).strip())
    return criteria


def parse_plan_steps(content: str) -> list[str]:
    """
    Parse numbered plan steps from phase content.

    Args:
        content: Phase content

    Returns:
        List of step strings
    """
    steps = []
    section = parse_section(content, "Plan")
    if section:
        # Match numbered items
        pattern = re.compile(r"^\d+\.\s*(.+)$", re.MULTILINE)
        for match in pattern.finditer(section):
            steps.append(match.group(1).strip())
    return steps


def parse_phase(content: str, line_start: int = 0) -> Phase:
    """
    Parse a single phase from its raw content.

    Args:
        content: Raw phase content (starting with ## Phase N:)
        line_start: Line number where this phase starts in original document

    Returns:
        Parsed Phase

    Raises:
        ParseError: If phase header is invalid
    """
    # Extract phase number and title from header
    header_match = PHASE_HEADER_PATTERN.search(content)
    if not header_match:
        raise ParseError("Invalid phase header", line_start)

    phase_num = int(header_match.group(1))
    title = header_match.group(2).strip()

    return Phase(
        number=phase_num,
        title=title,
        context=parse_section(content, "Context"),
        goal=parse_section(content, "Goal"),
        files=parse_files_table(content),
        plan=parse_plan_steps(content),
        implementation=parse_section(content, "Implementation"),
        verify=parse_section(content, "Verify"),
        acceptance_criteria=parse_acceptance_criteria(content),
        rollback=parse_section(content, "Rollback"),
        completion=parse_section(content, "Completion"),
        raw_content=content,
        line_start=line_start,
    )


def parse_audit_document(content: str, source_path: Path | None = None) -> AuditDocument:
    """
    Parse an audit document into structured form.

    Args:
        content: Raw markdown content
        source_path: Original file path (for error messages)

    Returns:
        Parsed AuditDocument

    Raises:
        ParseError: If document structure is invalid
    """
    # Extract document header
    header_match = DOCUMENT_HEADER_PATTERN.search(content)
    if not header_match:
        raise ParseError("Missing document header. Expected '# Document N: Title'")

    doc_number = int(header_match.group(1))
    doc_title = f"Document {doc_number}: {header_match.group(2).strip()}"

    # Extract setup block (required)
    setup_block = extract_setup_block(content)

    # Detect and parse phases
    boundaries = detect_phase_boundaries(content)
    if not boundaries:
        raise ParseError("No phases found. Expected '## Phase N:' headers.")

    phases = []
    for phase_num, start_idx, end_idx in boundaries:
        phase_content = content[start_idx:end_idx].rstrip()
        line_start = content[:start_idx].count("\n") + 1
        phases.append(parse_phase(phase_content, line_start))

    return AuditDocument(
        title=doc_title,
        document_number=doc_number,
        source_path=source_path,
        overview=extract_overview(content),
        prerequisites=extract_prerequisites(content),
        phases=phases,
        setup_block=setup_block,
        completion_block=extract_completion_block(content),
        raw_content=content,
    )


# =============================================================================
# Validation Functions
# =============================================================================


def validate_phase(phase: Phase) -> list[ValidationIssue]:
    """
    Validate a single phase.

    Args:
        phase: Parsed phase

    Returns:
        List of validation issues (errors and warnings)
    """
    issues = []
    n = phase.number
    line = phase.line_start

    # Required sections (errors)
    required_sections = [
        ("Context", phase.context),
        ("Goal", phase.goal),
        ("Files", len(phase.files) > 0 or "### Files" in phase.raw_content),
        ("Implementation", phase.implementation),
        ("Verify", phase.verify),
        ("Completion", phase.completion),
    ]

    for section_name, has_content in required_sections:
        if not has_content:
            issues.append(
                ValidationIssue(
                    level="error",
                    phase=n,
                    line=line,
                    message=f"Phase {n} missing required section: {section_name}",
                )
            )

    # Recommended sections (warnings)
    recommended_sections = [
        ("Plan", len(phase.plan) > 0),
        ("Acceptance Criteria", len(phase.acceptance_criteria) > 0),
        ("Rollback", phase.rollback),
    ]

    for section_name, has_content in recommended_sections:
        if not has_content:
            issues.append(
                ValidationIssue(
                    level="warning",
                    phase=n,
                    line=line,
                    message=f"Phase {n} missing section: {section_name}",
                )
            )

    # Token count validation
    tokens = phase.estimated_tokens
    if tokens >= TOKEN_ERROR_THRESHOLD:
        issues.append(
            ValidationIssue(
                level="error",
                phase=n,
                line=line,
                message=f"Phase {n} is ~{tokens:,} tokens (limit: 25,000). Must split phase.",
            )
        )
    elif tokens >= TOKEN_WARNING_THRESHOLD:
        issues.append(
            ValidationIssue(
                level="warning",
                phase=n,
                line=line,
                message=f"Phase {n} is ~{tokens:,} tokens. Consider splitting if issues occur.",
            )
        )

    # Code block language identifiers
    code_block_pattern = re.compile(r"```(\w*)\n", re.MULTILINE)
    for i, match in enumerate(code_block_pattern.finditer(phase.raw_content)):
        if not match.group(1):
            # Find approximate line number
            block_line = phase.raw_content[: match.start()].count("\n") + line
            issues.append(
                ValidationIssue(
                    level="warning",
                    phase=n,
                    line=block_line,
                    message=f"Phase {n}: Code block missing language identifier",
                )
            )

    # Verify section should have Expected comments
    if phase.verify and "# Expected:" not in phase.verify:
        issues.append(
            ValidationIssue(
                level="warning",
                phase=n,
                line=line,
                message=f"Phase {n}: Verify section missing '# Expected:' comments",
            )
        )

    return issues


def validate_document(
    content: str, source_path: Path | None = None
) -> ValidationResult:
    """
    Validate an audit document structure and content.

    Args:
        content: Raw markdown content
        source_path: Original file path (for error messages)

    Returns:
        ValidationResult with errors and warnings
    """
    errors: list[ValidationIssue] = []
    warnings: list[ValidationIssue] = []
    token_estimates: dict[str, int] = {}

    source_str = str(source_path) if source_path else None

    # Document header check
    header_match = DOCUMENT_HEADER_PATTERN.search(content)
    if not header_match:
        warnings.append(
            ValidationIssue(
                level="warning",
                phase=None,
                line=1,
                message="Missing document header. Expected '# Document N: Title'",
            )
        )
        doc_title = None
    else:
        doc_title = f"Document {header_match.group(1)}: {header_match.group(2).strip()}"

    # Document Overview check
    if "## Document Overview" not in content:
        warnings.append(
            ValidationIssue(
                level="warning",
                phase=None,
                line=None,
                message="Missing Document Overview section",
            )
        )

    # Prerequisites check
    prerequisites = extract_prerequisites(content)
    if not prerequisites:
        warnings.append(
            ValidationIssue(
                level="warning",
                phase=None,
                line=None,
                message="Missing Prerequisites section",
            )
        )
    else:
        # Check if baseline test count is parseable
        baseline = parse_baseline_test_count(prerequisites)
        if baseline == 0:
            warnings.append(
                ValidationIssue(
                    level="warning",
                    phase=None,
                    line=None,
                    message="Could not parse baseline test count from Prerequisites. Report will show 0 baseline tests.",
                )
            )

    # Setup block markers check
    if SETUP_START_MARKER not in content:
        errors.append(
            ValidationIssue(
                level="error",
                phase=None,
                line=None,
                message=f"Setup block not found. Expected '{SETUP_START_MARKER}' marker.",
            )
        )
    elif SETUP_END_MARKER not in content:
        errors.append(
            ValidationIssue(
                level="error",
                phase=None,
                line=None,
                message=f"Setup block not closed. Expected '{SETUP_END_MARKER}' marker.",
            )
        )

    # Phase detection
    boundaries = detect_phase_boundaries(content)
    if not boundaries:
        errors.append(
            ValidationIssue(
                level="error",
                phase=None,
                line=None,
                message="No phases found. Expected '## Phase N:' headers.",
            )
        )
        phase_count = 0
        phase_range = None
    else:
        phase_count = len(boundaries)
        phase_range = f"{boundaries[0][0]}-{boundaries[-1][0]}"

        # Check for sequential phases
        phase_nums = [b[0] for b in boundaries]
        for i in range(1, len(phase_nums)):
            if phase_nums[i] != phase_nums[i - 1] + 1:
                gap_start = phase_nums[i - 1]
                gap_end = phase_nums[i]
                missing = list(range(gap_start + 1, gap_end))
                warnings.append(
                    ValidationIssue(
                        level="warning",
                        phase=None,
                        line=None,
                        message=f"Phase gap detected: {gap_start} to {gap_end}. Missing phases: {missing}",
                    )
                )

        # Validate each phase
        total_tokens = 0
        for phase_num, start_idx, end_idx in boundaries:
            phase_content = content[start_idx:end_idx].rstrip()
            line_start = content[:start_idx].count("\n") + 1

            try:
                phase = parse_phase(phase_content, line_start)
                phase_issues = validate_phase(phase)

                for issue in phase_issues:
                    if issue.level == "error":
                        errors.append(issue)
                    else:
                        warnings.append(issue)

                tokens = phase.estimated_tokens
                token_estimates[f"phase_{phase_num}"] = tokens
                total_tokens += tokens

            except ParseError as e:
                errors.append(
                    ValidationIssue(
                        level="error",
                        phase=phase_num,
                        line=line_start,
                        message=f"Failed to parse Phase {phase_num}: {e}",
                    )
                )

        token_estimates["total"] = total_tokens

    # Document Completion check
    if "## Document Completion" not in content:
        warnings.append(
            ValidationIssue(
                level="warning",
                phase=None,
                line=None,
                message="Missing Document Completion section",
            )
        )

    return ValidationResult(
        valid=len(errors) == 0,
        errors=errors,
        warnings=warnings,
        source_path=source_str,
        document_title=doc_title,
        phase_count=phase_count,
        phase_range=phase_range,
        token_estimates=token_estimates,
    )


# =============================================================================
# File Generation Functions
# =============================================================================


def create_setup_file_content(content: str) -> str:
    """
    Create setup.md content by combining Prerequisites + setup block.

    Args:
        content: Full document content

    Returns:
        Combined content for setup.md (Prerequisites + setup block)
    """
    prereq = extract_prerequisites(content) or ""
    setup_block = extract_setup_block(content)

    if prereq:
        return prereq + "\n\n---\n\n" + setup_block
    return setup_block


def calculate_zero_padding(max_phase: int) -> int:
    """
    Calculate zero-padding width based on maximum phase number.

    Args:
        max_phase: Highest phase number in document

    Returns:
        Number of digits to pad to
    """
    return len(str(max_phase))


def write_phase_file(phase: Phase, output_path: Path) -> None:
    """
    Write a single phase to a file.

    Args:
        phase: Parsed phase
        output_path: Target file path
    """
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(phase.raw_content)


def write_metadata(project_dir: Path, baseline_tests: int) -> Path:
    """
    Write metadata files for execution tracking.

    Args:
        project_dir: Project directory
        baseline_tests: Baseline test count from Prerequisites

    Returns:
        Path to .audit-meta/ directory
    """
    meta_dir = project_dir / ".audit-meta"
    meta_dir.mkdir(parents=True, exist_ok=True)

    # Phaser version
    (meta_dir / "phaser-version").write_text(PHASER_VERSION)

    # Baseline test count
    (meta_dir / "baseline-tests").write_text(str(baseline_tests))

    # Note: base-commit is written by setup.md execution

    return meta_dir


def split_document(
    document: AuditDocument,
    output_dir: Path,
    project_dir: Path,
) -> tuple[Path, list[Path], Path]:
    """
    Split document into individual phase files.

    Args:
        document: Parsed audit document
        output_dir: Directory for phase files (created if needed)
        project_dir: Project root directory

    Returns:
        Tuple of (setup_file, phase_files, meta_dir)
    """
    # Create directories
    output_dir.mkdir(parents=True, exist_ok=True)

    # Write setup.md
    setup_content = create_setup_file_content(document.raw_content)
    setup_file = output_dir / "setup.md"
    setup_file.write_text(setup_content)

    # Calculate zero-padding
    max_phase = max(p.number for p in document.phases) if document.phases else 0
    padding = calculate_zero_padding(max_phase)

    # Write phase files
    phase_files = []
    for phase in document.phases:
        filename = f"phase-{str(phase.number).zfill(padding)}.md"
        phase_path = output_dir / filename
        write_phase_file(phase, phase_path)
        phase_files.append(phase_path)

    # Write metadata
    baseline = parse_baseline_test_count(document.prerequisites)
    meta_dir = write_metadata(project_dir, baseline)

    return setup_file, phase_files, meta_dir
