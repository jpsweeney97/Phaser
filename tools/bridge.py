"""
Audit Bridge - Seamless audit execution for Claude Code.

This module provides functionality to parse, validate, split, and execute
audit documents generated by Claude.ai.
"""

from __future__ import annotations

import re
import shutil
import subprocess
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any

# =============================================================================
# Constants
# =============================================================================

PHASER_VERSION = "1.6.2"

SETUP_START_MARKER = "=== AUDIT SETUP START ==="
SETUP_END_MARKER = "=== AUDIT SETUP END ==="

DOCUMENT_HEADER_PATTERN = re.compile(r"^# Document (\d+):\s*(.+)$", re.MULTILINE)
PHASE_HEADER_PATTERN = re.compile(r"^## Phase (\d+):\s*(.+)$", re.MULTILINE)
COMPLETION_HEADER_PATTERN = re.compile(r"^## Document Completion", re.MULTILINE)

TOKEN_WARNING_THRESHOLD = 20000
TOKEN_ERROR_THRESHOLD = 25000

# =============================================================================
# Errors
# =============================================================================


class BridgeError(Exception):
    """Base error for bridge operations."""

    pass


class ParseError(BridgeError):
    """Error parsing audit document."""

    def __init__(self, message: str, line: int | None = None):
        self.line = line
        full_message = f"{message}" + (f" (line {line})" if line else "")
        super().__init__(full_message)


class ValidationError(BridgeError):
    """Error validating audit document structure."""

    def __init__(self, message: str, issues: list[ValidationIssue] | None = None):
        self.issues = issues or []
        super().__init__(message)


class ExecutionError(BridgeError):
    """Error executing audit."""

    pass


# =============================================================================
# Enums
# =============================================================================


class FileAction(str, Enum):
    """Action type for files in a phase."""

    CREATE = "CREATE"
    MODIFY = "MODIFY"
    DELETE = "DELETE"


# =============================================================================
# Data Classes
# =============================================================================


@dataclass
class ValidationIssue:
    """A single validation error or warning."""

    level: str  # "error" or "warning"
    phase: int | None  # Phase number, or None for document-level
    line: int | None  # Line number, if applicable
    message: str  # Human-readable message

    def to_dict(self) -> dict[str, Any]:
        return {
            "level": self.level,
            "phase": self.phase,
            "line": self.line,
            "message": self.message,
        }


@dataclass
class ValidationResult:
    """Result of document validation."""

    valid: bool  # True if no errors
    errors: list[ValidationIssue] = field(default_factory=list)
    warnings: list[ValidationIssue] = field(default_factory=list)

    source_path: str | None = None
    document_title: str | None = None
    phase_count: int = 0
    phase_range: str | None = None
    token_estimates: dict[str, int] = field(default_factory=dict)

    def to_dict(self) -> dict[str, Any]:
        return {
            "file": self.source_path,
            "valid": self.valid,
            "document": {
                "title": self.document_title,
                "phases": self.phase_count,
                "phase_range": self.phase_range,
            },
            "errors": [e.to_dict() for e in self.errors],
            "warnings": [w.to_dict() for w in self.warnings],
            "tokens": self.token_estimates,
        }


@dataclass
class PhaseFile:
    """A file entry from the Files table."""

    path: str  # "tools/reverse.py"
    action: FileAction  # CREATE, MODIFY, DELETE
    purpose: str  # "Reverse audit module"

    def to_dict(self) -> dict[str, Any]:
        return {
            "path": self.path,
            "action": self.action.value,
            "purpose": self.purpose,
        }


@dataclass
class Phase:
    """A single phase from an audit document."""

    number: int  # 36
    title: str  # "Reverse Audit Specification"

    context: str = ""
    goal: str = ""
    files: list[PhaseFile] = field(default_factory=list)
    plan: list[str] = field(default_factory=list)
    implementation: str = ""
    verify: str = ""
    acceptance_criteria: list[str] = field(default_factory=list)
    rollback: str = ""
    completion: str = ""

    raw_content: str = ""
    line_start: int = 0

    @property
    def estimated_tokens(self) -> int:
        """Estimate token count (conservative: 1 token per 3.5 chars)."""
        return int(len(self.raw_content) / 3.5)

    def to_dict(self) -> dict[str, Any]:
        return {
            "number": self.number,
            "title": self.title,
            "files": [f.to_dict() for f in self.files],
            "estimated_tokens": self.estimated_tokens,
            "line_start": self.line_start,
        }


@dataclass
class AuditDocument:
    """Parsed audit document."""

    title: str  # "Document 7: Reverse Audit"
    document_number: int  # 7
    source_path: Path | None = None

    overview: str | None = None
    prerequisites: str | None = None

    phases: list[Phase] = field(default_factory=list)
    setup_block: str = ""
    completion_block: str | None = None

    raw_content: str = ""

    @property
    def phase_count(self) -> int:
        return len(self.phases)

    @property
    def phase_start(self) -> int:
        return self.phases[0].number if self.phases else 0

    @property
    def phase_end(self) -> int:
        return self.phases[-1].number if self.phases else 0

    @property
    def phase_range(self) -> str:
        return f"{self.phase_start}-{self.phase_end}"

    def to_dict(self) -> dict[str, Any]:
        return {
            "title": self.title,
            "document_number": self.document_number,
            "source_path": str(self.source_path) if self.source_path else None,
            "overview": self.overview,
            "prerequisites": self.prerequisites,
            "phases": [p.to_dict() for p in self.phases],
            "phase_start": self.phase_start,
            "phase_end": self.phase_end,
            "phase_count": self.phase_count,
        }


@dataclass
class PrepareResult:
    """Result of preparing an audit for execution."""

    document: AuditDocument
    validation: ValidationResult
    project_dir: Path
    audit_phases_dir: Path
    meta_dir: Path

    setup_file: Path
    phase_files: list[Path] = field(default_factory=list)
    audit_copy: Path | None = None

    prompt: str = ""

    def to_dict(self) -> dict[str, Any]:
        return {
            "document": self.document.to_dict(),
            "validation": self.validation.to_dict(),
            "project_dir": str(self.project_dir),
            "setup_file": str(self.setup_file),
            "phase_files": [str(p) for p in self.phase_files],
            "audit_copy": str(self.audit_copy) if self.audit_copy else None,
        }


# =============================================================================
# Parsing Functions
# =============================================================================


def estimate_tokens(text: str) -> int:
    """Estimate token count. Conservative: 1 token per 3.5 characters."""
    return int(len(text) / 3.5)


def extract_setup_block(content: str) -> str:
    """
    Extract setup block content between markers.

    Args:
        content: Full document content

    Returns:
        Setup block content (including markers)

    Raises:
        ParseError: If markers not found
    """
    start_idx = content.find(SETUP_START_MARKER)
    if start_idx == -1:
        raise ParseError(
            f"Setup block not found. Expected '{SETUP_START_MARKER}' marker."
        )

    end_idx = content.find(SETUP_END_MARKER)
    if end_idx == -1:
        raise ParseError(
            f"Setup block not closed. Expected '{SETUP_END_MARKER}' marker."
        )

    return content[start_idx : end_idx + len(SETUP_END_MARKER)]


def extract_prerequisites(content: str) -> str | None:
    """
    Extract Prerequisites section content.

    Args:
        content: Full document content

    Returns:
        Prerequisites content, or None if not found
    """
    pattern = re.compile(
        r"^## Prerequisites\s*\n(.*?)(?=^## |\Z)", re.MULTILINE | re.DOTALL
    )
    match = pattern.search(content)
    if match:
        return match.group(0).strip()
    return None


def parse_baseline_test_count(prerequisites: str | None) -> int:
    """
    Parse the baseline test count from Prerequisites section.

    Args:
        prerequisites: Prerequisites section content

    Returns:
        Baseline test count (0 if not found or unparseable)
    """
    if not prerequisites:
        return 0

    # Look for patterns like "280+ passed" or "Expected: 280+ passed"
    pattern = re.compile(r"(\d+)\+?\s*passed", re.IGNORECASE)
    match = pattern.search(prerequisites)
    if match:
        return int(match.group(1))
    return 0


def extract_overview(content: str) -> str | None:
    """
    Extract Document Overview section content.

    Args:
        content: Full document content

    Returns:
        Overview content, or None if not found
    """
    pattern = re.compile(
        r"^## Document Overview\s*\n(.*?)(?=^## |\n---|\Z)", re.MULTILINE | re.DOTALL
    )
    match = pattern.search(content)
    if match:
        return match.group(1).strip()
    return None


def extract_completion_block(content: str) -> str | None:
    """
    Extract Document Completion section content.

    Args:
        content: Full document content

    Returns:
        Completion content, or None if not found
    """
    match = COMPLETION_HEADER_PATTERN.search(content)
    if match:
        return content[match.start() :].strip()
    return None


def find_code_block_ranges(content: str) -> list[tuple[int, int]]:
    """
    Find all fenced code block ranges using state tracking.

    Uses line-by-line state tracking instead of regex to correctly handle
    nested backticks, code examples containing markdown, and other edge cases.

    Args:
        content: Document content

    Returns:
        List of (start, end) tuples for each code block
    """
    ranges = []
    lines = content.split('\n')
    in_block = False
    block_start = 0
    current_pos = 0

    for line in lines:
        # Check if line starts with ``` (fence marker)
        stripped = line.lstrip()
        if stripped.startswith('```'):
            if not in_block:
                # Entering a code block
                in_block = True
                block_start = current_pos
            else:
                # Exiting a code block
                in_block = False
                block_end = current_pos + len(line)
                ranges.append((block_start, block_end))

        current_pos += len(line) + 1  # +1 for newline

    # Handle unclosed code block (extends to end of document)
    if in_block:
        ranges.append((block_start, len(content)))

    return ranges


def is_inside_code_block(pos: int, code_block_ranges: list[tuple[int, int]]) -> bool:
    """
    Check if a position is inside any code block.

    Args:
        pos: Position in content
        code_block_ranges: List of (start, end) tuples from find_code_block_ranges

    Returns:
        True if position is inside a code block
    """
    return any(start <= pos < end for start, end in code_block_ranges)


def detect_phase_boundaries(content: str) -> list[tuple[int, int, int]]:
    """
    Detect phase boundaries in document, ignoring patterns inside code blocks.

    Args:
        content: Full document content

    Returns:
        List of (phase_number, start_index, end_index) tuples
    """
    # Find all code block ranges first
    code_block_ranges = find_code_block_ranges(content)

    boundaries = []
    matches = list(PHASE_HEADER_PATTERN.finditer(content))

    # Filter out matches that are inside code blocks
    real_matches = [
        m for m in matches if not is_inside_code_block(m.start(), code_block_ranges)
    ]

    for i, match in enumerate(real_matches):
        phase_num = int(match.group(1))
        start_idx = match.start()

        # End is either next phase, Document Completion, or end of content
        if i + 1 < len(real_matches):
            end_idx = real_matches[i + 1].start()
        else:
            # Check for Document Completion (skip ones inside code blocks)
            end_idx = len(content)
            search_pos = start_idx
            while True:
                completion_match = COMPLETION_HEADER_PATTERN.search(content, search_pos)
                if not completion_match:
                    break
                if not is_inside_code_block(
                    completion_match.start(), code_block_ranges
                ):
                    end_idx = completion_match.start()
                    break
                # Move past this match and continue searching
                search_pos = completion_match.end()

        boundaries.append((phase_num, start_idx, end_idx))

    return boundaries


def parse_files_table(content: str) -> list[PhaseFile]:
    """
    Parse the Files table from phase content.

    Args:
        content: Phase content containing Files section

    Returns:
        List of PhaseFile objects
    """
    files = []

    # Find the Files section
    files_match = re.search(
        r"### Files\s*\n(.*?)(?=^### |\Z)", content, re.MULTILINE | re.DOTALL
    )
    if not files_match:
        return files

    table_content = files_match.group(1)

    # Parse table rows (skip header and separator)
    row_pattern = re.compile(r"\|\s*`?([^`|]+)`?\s*\|\s*(\w+)\s*\|\s*([^|]+)\s*\|")
    for match in row_pattern.finditer(table_content):
        path = match.group(1).strip()
        action_str = match.group(2).strip().upper()
        purpose = match.group(3).strip()

        # Skip header row
        if path.lower() in ("file", "---", "------"):
            continue

        try:
            action = FileAction(action_str)
            files.append(PhaseFile(path=path, action=action, purpose=purpose))
        except ValueError:
            # Invalid action, skip
            pass

    return files


def parse_section(content: str, section_name: str) -> str:
    """
    Parse a specific section from phase content.

    Args:
        content: Phase content
        section_name: Name of section (e.g., "Context", "Goal")

    Returns:
        Section content, or empty string if not found
    """
    pattern = re.compile(
        rf"^### {section_name}\s*\n(.*?)(?=^### |\Z)", re.MULTILINE | re.DOTALL
    )
    match = pattern.search(content)
    if match:
        return match.group(1).strip()
    return ""


def parse_acceptance_criteria(content: str) -> list[str]:
    """
    Parse acceptance criteria checkboxes from phase content.

    Args:
        content: Phase content

    Returns:
        List of criteria strings
    """
    criteria = []
    section = parse_section(content, "Acceptance Criteria")
    if section:
        # Match checkbox items
        pattern = re.compile(r"^- \[[ x]\]\s*(.+)$", re.MULTILINE)
        for match in pattern.finditer(section):
            criteria.append(match.group(1).strip())
    return criteria


def parse_plan_steps(content: str) -> list[str]:
    """
    Parse numbered plan steps from phase content.

    Args:
        content: Phase content

    Returns:
        List of step strings
    """
    steps = []
    section = parse_section(content, "Plan")
    if section:
        # Match numbered items
        pattern = re.compile(r"^\d+\.\s*(.+)$", re.MULTILINE)
        for match in pattern.finditer(section):
            steps.append(match.group(1).strip())
    return steps


def parse_phase(content: str, line_start: int = 0) -> Phase:
    """
    Parse a single phase from its raw content.

    Args:
        content: Raw phase content (starting with ## Phase N:)
        line_start: Line number where this phase starts in original document

    Returns:
        Parsed Phase

    Raises:
        ParseError: If phase header is invalid
    """
    # Extract phase number and title from header
    header_match = PHASE_HEADER_PATTERN.search(content)
    if not header_match:
        raise ParseError("Invalid phase header", line_start)

    phase_num = int(header_match.group(1))
    title = header_match.group(2).strip()

    return Phase(
        number=phase_num,
        title=title,
        context=parse_section(content, "Context"),
        goal=parse_section(content, "Goal"),
        files=parse_files_table(content),
        plan=parse_plan_steps(content),
        implementation=parse_section(content, "Implementation"),
        verify=parse_section(content, "Verify"),
        acceptance_criteria=parse_acceptance_criteria(content),
        rollback=parse_section(content, "Rollback"),
        completion=parse_section(content, "Completion"),
        raw_content=content,
        line_start=line_start,
    )


def parse_audit_document(content: str, source_path: Path | None = None) -> AuditDocument:
    """
    Parse an audit document into structured form.

    Args:
        content: Raw markdown content
        source_path: Original file path (for error messages)

    Returns:
        Parsed AuditDocument

    Raises:
        ParseError: If document structure is invalid
    """
    # Extract document header
    header_match = DOCUMENT_HEADER_PATTERN.search(content)
    if not header_match:
        raise ParseError("Missing document header. Expected '# Document N: Title'")

    doc_number = int(header_match.group(1))
    doc_title = f"Document {doc_number}: {header_match.group(2).strip()}"

    # Extract setup block (required)
    setup_block = extract_setup_block(content)

    # Detect and parse phases
    boundaries = detect_phase_boundaries(content)
    if not boundaries:
        raise ParseError("No phases found. Expected '## Phase N:' headers.")

    phases = []
    for phase_num, start_idx, end_idx in boundaries:
        phase_content = content[start_idx:end_idx].rstrip()
        line_start = content[:start_idx].count("\n") + 1
        phases.append(parse_phase(phase_content, line_start))

    return AuditDocument(
        title=doc_title,
        document_number=doc_number,
        source_path=source_path,
        overview=extract_overview(content),
        prerequisites=extract_prerequisites(content),
        phases=phases,
        setup_block=setup_block,
        completion_block=extract_completion_block(content),
        raw_content=content,
    )


# =============================================================================
# Validation Functions
# =============================================================================


def validate_phase(phase: Phase) -> list[ValidationIssue]:
    """
    Validate a single phase.

    Args:
        phase: Parsed phase

    Returns:
        List of validation issues (errors and warnings)
    """
    issues = []
    n = phase.number
    line = phase.line_start

    # Required sections (errors)
    required_sections = [
        ("Context", phase.context),
        ("Goal", phase.goal),
        ("Files", len(phase.files) > 0 or "### Files" in phase.raw_content),
        ("Implementation", phase.implementation),
        ("Verify", phase.verify),
        ("Completion", phase.completion),
    ]

    for section_name, has_content in required_sections:
        if not has_content:
            issues.append(
                ValidationIssue(
                    level="error",
                    phase=n,
                    line=line,
                    message=f"Phase {n} missing required section: {section_name}",
                )
            )

    # Recommended sections (warnings)
    recommended_sections = [
        ("Plan", len(phase.plan) > 0),
        ("Acceptance Criteria", len(phase.acceptance_criteria) > 0),
        ("Rollback", phase.rollback),
    ]

    for section_name, has_content in recommended_sections:
        if not has_content:
            issues.append(
                ValidationIssue(
                    level="warning",
                    phase=n,
                    line=line,
                    message=f"Phase {n} missing section: {section_name}",
                )
            )

    # Token count validation
    tokens = phase.estimated_tokens
    if tokens >= TOKEN_ERROR_THRESHOLD:
        issues.append(
            ValidationIssue(
                level="error",
                phase=n,
                line=line,
                message=f"Phase {n} is ~{tokens:,} tokens (limit: 25,000). Must split phase.",
            )
        )
    elif tokens >= TOKEN_WARNING_THRESHOLD:
        issues.append(
            ValidationIssue(
                level="warning",
                phase=n,
                line=line,
                message=f"Phase {n} is ~{tokens:,} tokens. Consider splitting if issues occur.",
            )
        )

    # Code block language identifiers
    code_block_pattern = re.compile(r"```(\w*)\n", re.MULTILINE)
    for i, match in enumerate(code_block_pattern.finditer(phase.raw_content)):
        if not match.group(1):
            # Find approximate line number
            block_line = phase.raw_content[: match.start()].count("\n") + line
            issues.append(
                ValidationIssue(
                    level="warning",
                    phase=n,
                    line=block_line,
                    message=f"Phase {n}: Code block missing language identifier",
                )
            )

    # Verify section should have Expected comments
    if phase.verify and "# Expected:" not in phase.verify:
        issues.append(
            ValidationIssue(
                level="warning",
                phase=n,
                line=line,
                message=f"Phase {n}: Verify section missing '# Expected:' comments",
            )
        )

    return issues


def validate_document(
    content: str, source_path: Path | None = None
) -> ValidationResult:
    """
    Validate an audit document structure and content.

    Args:
        content: Raw markdown content
        source_path: Original file path (for error messages)

    Returns:
        ValidationResult with errors and warnings
    """
    errors: list[ValidationIssue] = []
    warnings: list[ValidationIssue] = []
    token_estimates: dict[str, int] = {}

    source_str = str(source_path) if source_path else None

    # Document header check
    header_match = DOCUMENT_HEADER_PATTERN.search(content)
    if not header_match:
        warnings.append(
            ValidationIssue(
                level="warning",
                phase=None,
                line=1,
                message="Missing document header. Expected '# Document N: Title'",
            )
        )
        doc_title = None
    else:
        doc_title = f"Document {header_match.group(1)}: {header_match.group(2).strip()}"

    # Document Overview check
    if "## Document Overview" not in content:
        warnings.append(
            ValidationIssue(
                level="warning",
                phase=None,
                line=None,
                message="Missing Document Overview section",
            )
        )

    # Prerequisites check
    prerequisites = extract_prerequisites(content)
    if not prerequisites:
        warnings.append(
            ValidationIssue(
                level="warning",
                phase=None,
                line=None,
                message="Missing Prerequisites section",
            )
        )
    else:
        # Check if baseline test count is parseable
        baseline = parse_baseline_test_count(prerequisites)
        if baseline == 0:
            warnings.append(
                ValidationIssue(
                    level="warning",
                    phase=None,
                    line=None,
                    message="Could not parse baseline test count from Prerequisites. Report will show 0 baseline tests.",
                )
            )

    # Setup block markers check
    if SETUP_START_MARKER not in content:
        errors.append(
            ValidationIssue(
                level="error",
                phase=None,
                line=None,
                message=f"Setup block not found. Expected '{SETUP_START_MARKER}' marker.",
            )
        )
    elif SETUP_END_MARKER not in content:
        errors.append(
            ValidationIssue(
                level="error",
                phase=None,
                line=None,
                message=f"Setup block not closed. Expected '{SETUP_END_MARKER}' marker.",
            )
        )

    # Phase detection
    boundaries = detect_phase_boundaries(content)
    if not boundaries:
        errors.append(
            ValidationIssue(
                level="error",
                phase=None,
                line=None,
                message="No phases found. Expected '## Phase N:' headers.",
            )
        )
        phase_count = 0
        phase_range = None
    else:
        phase_count = len(boundaries)
        phase_range = f"{boundaries[0][0]}-{boundaries[-1][0]}"

        # Check for sequential phases
        phase_nums = [b[0] for b in boundaries]
        for i in range(1, len(phase_nums)):
            if phase_nums[i] != phase_nums[i - 1] + 1:
                gap_start = phase_nums[i - 1]
                gap_end = phase_nums[i]
                missing = list(range(gap_start + 1, gap_end))
                warnings.append(
                    ValidationIssue(
                        level="warning",
                        phase=None,
                        line=None,
                        message=f"Phase gap detected: {gap_start} to {gap_end}. Missing phases: {missing}",
                    )
                )

        # Validate each phase
        total_tokens = 0
        for phase_num, start_idx, end_idx in boundaries:
            phase_content = content[start_idx:end_idx].rstrip()
            line_start = content[:start_idx].count("\n") + 1

            try:
                phase = parse_phase(phase_content, line_start)
                phase_issues = validate_phase(phase)

                for issue in phase_issues:
                    if issue.level == "error":
                        errors.append(issue)
                    else:
                        warnings.append(issue)

                tokens = phase.estimated_tokens
                token_estimates[f"phase_{phase_num}"] = tokens
                total_tokens += tokens

            except ParseError as e:
                errors.append(
                    ValidationIssue(
                        level="error",
                        phase=phase_num,
                        line=line_start,
                        message=f"Failed to parse Phase {phase_num}: {e}",
                    )
                )

        token_estimates["total"] = total_tokens

    # Document Completion check
    if "## Document Completion" not in content:
        warnings.append(
            ValidationIssue(
                level="warning",
                phase=None,
                line=None,
                message="Missing Document Completion section",
            )
        )

    return ValidationResult(
        valid=len(errors) == 0,
        errors=errors,
        warnings=warnings,
        source_path=source_str,
        document_title=doc_title,
        phase_count=phase_count,
        phase_range=phase_range,
        token_estimates=token_estimates,
    )


# =============================================================================
# File Generation Functions
# =============================================================================


def create_setup_file_content(content: str) -> str:
    """
    Create setup.md content by combining Prerequisites + setup block.

    Args:
        content: Full document content

    Returns:
        Combined content for setup.md (Prerequisites + setup block)
    """
    prereq = extract_prerequisites(content) or ""
    setup_block = extract_setup_block(content)

    if prereq:
        return prereq + "\n\n---\n\n" + setup_block
    return setup_block


def calculate_zero_padding(max_phase: int) -> int:
    """
    Calculate zero-padding width based on maximum phase number.

    Args:
        max_phase: Highest phase number in document

    Returns:
        Number of digits to pad to
    """
    return len(str(max_phase))


def write_phase_file(phase: Phase, output_path: Path) -> None:
    """
    Write a single phase to a file.

    Args:
        phase: Parsed phase
        output_path: Target file path
    """
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(phase.raw_content)


def write_metadata(project_dir: Path, baseline_tests: int) -> Path:
    """
    Write metadata files for execution tracking.

    Args:
        project_dir: Project directory
        baseline_tests: Baseline test count from Prerequisites

    Returns:
        Path to .audit-meta/ directory
    """
    meta_dir = project_dir / ".audit-meta"
    meta_dir.mkdir(parents=True, exist_ok=True)

    # Phaser version
    (meta_dir / "phaser-version").write_text(PHASER_VERSION)

    # Baseline test count
    (meta_dir / "baseline-tests").write_text(str(baseline_tests))

    # Note: base-commit is written by setup.md execution

    return meta_dir


def split_document(
    document: AuditDocument,
    output_dir: Path,
    project_dir: Path,
) -> tuple[Path, list[Path], Path]:
    """
    Split document into individual phase files.

    Args:
        document: Parsed audit document
        output_dir: Directory for phase files (created if needed)
        project_dir: Project root directory

    Returns:
        Tuple of (setup_file, phase_files, meta_dir)
    """
    # Create directories
    output_dir.mkdir(parents=True, exist_ok=True)

    # Write setup.md
    setup_content = create_setup_file_content(document.raw_content)
    setup_file = output_dir / "setup.md"
    setup_file.write_text(setup_content)

    # Calculate zero-padding
    max_phase = max(p.number for p in document.phases) if document.phases else 0
    padding = calculate_zero_padding(max_phase)

    # Write phase files
    phase_files = []
    for phase in document.phases:
        filename = f"phase-{str(phase.number).zfill(padding)}.md"
        phase_path = output_dir / filename
        write_phase_file(phase, phase_path)
        phase_files.append(phase_path)

    # Write metadata
    baseline = parse_baseline_test_count(document.prerequisites)
    meta_dir = write_metadata(project_dir, baseline)

    return setup_file, phase_files, meta_dir


# =============================================================================
# Prompt Generation
# =============================================================================

EXECUTION_PROMPT_TEMPLATE = '''Execute audit-phases/setup.md first, then execute audit-phases/phase-{start}.md through phase-{end}.md in order.

IMPORTANT: During setup.md execution, after creating the git branch, run:
  mkdir -p .audit-meta
  git rev-parse HEAD > .audit-meta/base-commit
This captures the base commit for the execution report.

For each phase:
1. Read the phase file completely before starting
2. Execute all steps in the Implementation section exactly as specified
3. Run all Verify commands and confirm they produce the expected output
4. If any verification fails, debug and fix the issue, then re-run verification until it passes
5. Execute the Completion section (update CURRENT.md, git add, git commit)
6. Proceed immediately to the next phase without pausing

After all phases complete, generate EXECUTION_REPORT.md:

1. Read metadata files:
   - Base commit: cat .audit-meta/base-commit
   - Baseline tests: cat .audit-meta/baseline-tests
   - Phaser version: cat .audit-meta/phaser-version

2. Capture current state:
   - Run: git rev-parse --abbrev-ref HEAD (capture branch name)
   - Run: python -m pytest tests/ -q (capture test output and count)
   - Run: git log --oneline $(cat .audit-meta/base-commit)..HEAD (capture commit history)
   - Run: git diff --stat $(cat .audit-meta/base-commit)..HEAD (capture files changed)

3. Write EXECUTION_REPORT.md with this structure:

# Execution Report: {document_name}

## Metadata

| Field | Value |
|-------|-------|
| Audit Document | {source_filename} |
| Document Title | {document_name} |
| Project | [directory name from pwd] |
| Project Path | [absolute path from pwd] |
| Branch | [from git rev-parse --abbrev-ref HEAD] |
| Base Commit | [from .audit-meta/base-commit] |
| Started | [ISO8601 timestamp - record at start of setup.md] |
| Completed | [ISO8601 timestamp - now] |
| Phaser Version | [from .audit-meta/phaser-version] |

## Execution Summary

**Result:** [✅ All phases completed | ⚠️ Completed with issues | ❌ Failed]

**Phases:** [completed count] of {phase_count} completed

| Phase | Title | Status | Commit |
|-------|-------|--------|--------|
[One row per phase - extract title from phase file, commit from git log]

## Test Results

**Baseline:** [from .audit-meta/baseline-tests] tests
**Final:** [count from pytest output] tests
**Delta:** +[difference] tests

```
[Full pytest output]
```

## Git History

**Branch:** [branch name]
**Commits:** [count]

```
[Output of git log --oneline base-commit..HEAD]
```

## Files Changed

**Summary:** [from git diff --stat summary line]

```
[Output of git diff --stat base-commit..HEAD]
```

## Audit Objectives

From Document Overview:

> [Quote the Document Overview section from AUDIT.md]

## Acceptance Criteria Status

| Phase | Criterion | Status |
|-------|-----------|--------|
[For each phase, list each acceptance criterion with ✅ or ❌]

## Issues Encountered

[List any issues that occurred during execution and how they were resolved.
If no issues: "No issues encountered during execution."
NOTE: This section may be incomplete - Claude Code may not recall all issues.]

## Post-Execution Checklist

For human review:

- [ ] Review git diff for unintended changes
- [ ] Run manual smoke tests
- [ ] Merge to main when ready
- [ ] Tag release if applicable
- [ ] Archive AUDIT.md if desired

## Rollback Instructions

To undo this entire audit:

```bash
git checkout main
git branch -D [audit branch name]
```

4. Commit the report:
   git add EXECUTION_REPORT.md
   git commit -m "Add execution report for {document_name}"

Continue automatically without pausing for confirmation. Fix all errors autonomously. Do not ask for permission.'''


def generate_execution_prompt(
    document: AuditDocument,
    source_filename: str,
) -> str:
    """
    Generate the execution prompt for Claude Code.

    Args:
        document: Parsed audit document
        source_filename: Original audit filename

    Returns:
        Complete prompt string
    """
    return EXECUTION_PROMPT_TEMPLATE.format(
        start=document.phase_start,
        end=document.phase_end,
        phase_count=document.phase_count,
        document_name=document.title,
        source_filename=source_filename,
    )


# =============================================================================
# Execution Functions
# =============================================================================


def launch_claude_code(
    prompt: str,
    project_dir: Path,
    skip_permissions: bool = True,
) -> subprocess.Popen:
    """
    Launch Claude Code with the execution prompt via stdin.

    Note: The -p flag assumes Claude Code reads prompts from stdin.
    Verify against Claude Code's actual CLI documentation and adjust if needed.

    Args:
        prompt: Execution prompt
        project_dir: Project directory to run in
        skip_permissions: Whether to use --dangerously-skip-permissions

    Returns:
        Claude Code process handle
    """
    cmd = ["claude"]

    if skip_permissions:
        cmd.append("--dangerously-skip-permissions")

    cmd.append("-p")  # Read prompt from stdin

    process = subprocess.Popen(
        cmd,
        cwd=project_dir,
        stdin=subprocess.PIPE,
        text=True,
    )

    if process.stdin:
        process.stdin.write(prompt)
        process.stdin.close()

    return process


def prepare_audit(
    audit_path: Path,
    project_dir: Path | None = None,
    output_dir: Path | None = None,
    skip_validation: bool = False,
    force: bool = False,
) -> PrepareResult:
    """
    Prepare an audit for execution.

    Args:
        audit_path: Path to audit document
        project_dir: Target project (default: current directory)
        output_dir: Phase files directory (default: ./audit-phases)
        skip_validation: Skip validation checks
        force: Overwrite existing audit-phases/ directory

    Returns:
        PrepareResult with all paths and prompt

    Raises:
        ParseError: If document invalid
        ValidationError: If validation fails with errors
        FileNotFoundError: If audit file not found
        FileExistsError: If audit-phases/ exists and not --force
    """
    # Resolve paths
    audit_path = Path(audit_path).resolve()
    if not audit_path.exists():
        raise FileNotFoundError(f"Audit file not found: {audit_path}")

    project_dir = Path(project_dir).resolve() if project_dir else Path.cwd()
    output_dir = project_dir / (output_dir or "audit-phases")

    # Check for existing directory
    if output_dir.exists() and not force:
        raise FileExistsError(
            f"Directory {output_dir.name}/ already exists. Use --force to overwrite."
        )

    # Read and parse document
    content = audit_path.read_text()
    document = parse_audit_document(content, audit_path)

    # Validate unless skipped
    if skip_validation:
        validation = ValidationResult(
            valid=True,
            source_path=str(audit_path),
            document_title=document.title,
            phase_count=document.phase_count,
            phase_range=document.phase_range,
        )
    else:
        validation = validate_document(content, audit_path)
        if not validation.valid:
            raise ValidationError(
                f"Validation failed with {len(validation.errors)} error(s).",
                validation.errors,
            )

    # Clean existing directory if --force
    if output_dir.exists() and force:
        shutil.rmtree(output_dir)

    # Split document into files
    setup_file, phase_files, meta_dir = split_document(
        document, output_dir, project_dir
    )

    # Copy original audit to project root (avoid SameFileError on case-insensitive filesystems)
    audit_copy = project_dir / "AUDIT.md"
    try:
        if not audit_path.samefile(audit_copy):
            shutil.copy2(audit_path, audit_copy)
    except FileNotFoundError:
        # audit_copy doesn't exist yet, safe to copy
        shutil.copy2(audit_path, audit_copy)

    # Generate prompt
    prompt = generate_execution_prompt(document, audit_path.name)

    return PrepareResult(
        document=document,
        validation=validation,
        project_dir=project_dir,
        audit_phases_dir=output_dir,
        meta_dir=meta_dir,
        setup_file=setup_file,
        phase_files=phase_files,
        audit_copy=audit_copy,
        prompt=prompt,
    )


def execute_audit(
    audit_path: Path,
    project_dir: Path | None = None,
    output_dir: Path | None = None,
    skip_permissions: bool = True,
    skip_validation: bool = False,
    force: bool = False,
) -> tuple[PrepareResult, subprocess.Popen]:
    """
    Prepare and execute an audit.

    Args:
        audit_path: Path to audit document
        project_dir: Target project (default: current directory)
        output_dir: Phase files directory (default: ./audit-phases)
        skip_permissions: Use --dangerously-skip-permissions flag
        skip_validation: Skip validation checks
        force: Overwrite existing audit-phases/ directory

    Returns:
        Tuple of (PrepareResult, Claude Code process handle)

    Raises:
        ParseError: If document invalid
        ValidationError: If validation fails
        FileNotFoundError: If audit file or claude not found
        FileExistsError: If audit-phases/ exists and not --force
    """
    # Check Claude Code is installed
    if not shutil.which("claude"):
        raise ExecutionError(
            "Claude Code not found. Install from https://claude.ai/code"
        )

    # Prepare the audit
    result = prepare_audit(
        audit_path=audit_path,
        project_dir=project_dir,
        output_dir=output_dir,
        skip_validation=skip_validation,
        force=force,
    )

    # Launch Claude Code
    process = launch_claude_code(
        prompt=result.prompt,
        project_dir=result.project_dir,
        skip_permissions=skip_permissions,
    )

    return result, process
